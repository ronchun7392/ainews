---
layout: post
title: Google releases Search Live voice search, which can be done directly by talking to the search engine.
date: 2025-07-08 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/google-search-live_1.jpg
icon: chat
---
* content
{:toc}

Google officially released **Search Live**, which is a brand-new **Voice Experience **.
**Search Live** integrates the capabilities of the Genesis AI technology (Gemini Model) and the traditional search engine, allowing you to interact with the search engine like a dialogue.
Compared to the traditional "Input keywords to look at the search results", Seech Live allows you to ask questions, listen to voice answers and follow up on questions on a continuous basis** The whole process is like communicating in real time with a "intellectual assistant".
It is currently being launched in the form of an “AI Mode experiment” among Android and iOS users in the United States region.

# Core functions include:

- A natural, fluid voice conversation with GoogleSearch**;

- It can be used seamlessly in multitasking contexts, such as moving, packing and household chores;

- Support for continuous follow-up on a question-to-answer basis;

- Presenting links to relevant web pages** for further browsing;

![](https://assets-v2.circle.so/77qt7jogrlw97j8aqfwy71gndqei)
Example scene: How do you use it in reality?
** When packing, **: "How do I take the saliva to be unwrinkled?" ** AI directs the voice response and gives the web link.
** When I was cooking **: "What's the quickest way to go with the tomatoes and the eggs in the fridge?" ** Cooking and listening to advice and reading the recipe page.
** On the way to the car**: "What's going on in Chicago today?"

# # The power to be supported #
Google plans to further upgrade the Seech Live mode in the coming months by adding **Visual recognition**:
Users can “show” what they see by the camera, and Google will respond in combination with voice input and visual images.
This will bring the search experience into the "multi-model interaction" phase, not just you ask, AI answers, but ** "You say + you see, AI understands together."**

# How do you use it?
Open Google App;
Click on the new **Live icon**;
Directly asking questions such as: “How do we prevent the fetters from wrinkle in the trunks?”
Receive an AI audio response (for continuation: "What if it is still wrinkled?");
View text or continue typing questions;
Recall dialogue at all times in the “AI Mode history record”;

# The technology behind it: Gemini+Search integration
Gemini-based voice-generated model

- Understanding the context and generating high-quality voice responses;

- A natural language fluidity and logical integrity of the answer;

Search engine system supports the source of information

- All responses based on Google search databases and web ecology;

- Provision of information links** that are genuinely accessible** and not limited to the subjective expression of AI only;

“Query Fan-out” technology

- Generate multiple query directions for one question and provide a richer web content result;

- Users not only get answers but also “expand awareness”;

# The meaning of user experience and industry
** Search from keyword ** real-time dialogue interactive**

-Search is no longer an ice-cold query box, but a "accompanied assistant experience";

- AI can respond and make recommendations in a more complex and vague context.

** Lower threshold for access to information**

- Fits for busy situations in which equipment cannot be operated by hand;

- Reduced user reliance on keyword tectonic techniques and more natural interaction with search systems.

** The assurance of the credibility of the information**

- Unlike some purely AI chat systems, Search Live continues to rely on web resources to provide clear and verifiable sources;

- To achieve a mixed interactive experience of the Generated AI+ Real Network.

Try: https://labs.google.com/search/Experiment/22 (need to switch to US IP)

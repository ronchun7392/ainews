---
layout: post
title: Google displays Android XR smart glasses prototypes for long-term memory, real-time voice interaction, automatic help based on user behaviour
date: 2025-07-02 12:00:00 +0800
category: Frontier Trends
thumbnail: /style/image/google-android-xr_1.jpg
icon: link
---
* content
{:toc}

Google displayed the prototype Android XR smart glasses at Google I/O 2025 and announced the integration of its advanced Gemini AI model into a new Android XR platform, making it its first “**The Android platform for the Gemini era**”.
**Target** Provides natural, immersed, real-time AI experiences through headwear equipment (e.g. smart glasses, AR/VR head displays, etc.) so that an AI assistant can “see what you see”, understand the scene and provide immediate help.
Android XR smart glasses do.

- **The context understands:** The user perspective is captured through cameras and microphones, and the current scene and tasks are understood in the context of geographic information.

- ** Voice interaction:** Voice helpers are activated at any time, no need to wake up manually, no need to use a mobile phone.

- ** Real-time aids: ** Automatically recommended actions based on user behaviour, such as navigation, data checking, photographing, translation, etc.

- **Memory and personalization:** long-term mission memory function, understanding user preferences, context.

- Integration with Gemini, real visual assistant.

Google demonstrated at the I/O Congress **the realistic use of Android XR devices**, covering the following capabilities:
![](https://assets-v2.circle.so/6rfq2nt67ub4pa4se5bf6z4c2nc6)实时翻译
Map Navigator
Real-time access to information and responses
Photos and videos
This marks Google moving towards the "AI+ Hardware+Operational System" integration platform.
Gemini will become the intelligent layer of the real world and is no longer confined to the screen.
Google also disclosed the key hardware specifications of the current prototype of smart glasses:

-  ** Camera**: for visual recognition, AR scene capture;

- **Microphone**: receiving voice commands and using them for environmental sound processing;

-  speaker**: provision of voice feedback, navigation aircasts, etc.;

-  Display of information in the lens** (optional): private projection information on the lens, not hologram/AR display, but with basic alarm and subtitle functions;

-  ** Working with mobile phones**: The glasses themselves are not stand-alone equipment, and data processing and display are separated by pairing Bluetooth/Wi-Fi with Android mobile phones.

To ensure that glasses are fashionable and wearable, Google is working with several brands:
![](https://assets-v2.circle.so/9wj1custf3udxt3dge3173an459m)